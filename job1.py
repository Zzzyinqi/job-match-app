import streamlit as st
import os
import re
import fitz  # PyMuPDF
from docx import Document
import pandas as pd
from datetime import datetime
import difflib

# åˆ›å»ºä¸Šä¼ ç›®å½•
UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

def extract_text_from_pdf(file_path):
    """ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    text = ""
    with fitz.open(file_path) as doc:
        for page in doc:
            text += page.get_text()
    return text

def extract_text_from_docx(file_path):
    """ä»DOCXæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    doc = Document(file_path)
    return "\n".join([para.text for para in doc.paragraphs])

def extract_text_from_txt(file_path):
    """ä»TXTæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

def normalize_position(position):
    """æ ‡å‡†åŒ–å²—ä½åç§°"""
    if not position:
        return ""
    
    # å¸¸è§å²—ä½åç§°æ˜ å°„
    position_mapping = {
        'å‰ç«¯': 'å‰ç«¯å¼€å‘', 'webå‰ç«¯': 'å‰ç«¯å¼€å‘', 'å‰ç«¯å·¥ç¨‹å¸ˆ': 'å‰ç«¯å¼€å‘',
        'åç«¯': 'åç«¯å¼€å‘', 'java': 'Javaå¼€å‘', 'python': 'Pythonå¼€å‘',
        'ui': 'UIè®¾è®¡', 'ç¾å·¥': 'UIè®¾è®¡', 'è§†è§‰è®¾è®¡': 'UIè®¾è®¡',
        'æµ‹è¯•': 'è½¯ä»¶æµ‹è¯•', 'qa': 'è½¯ä»¶æµ‹è¯•', 'æµ‹è¯•å·¥ç¨‹å¸ˆ': 'è½¯ä»¶æµ‹è¯•',
        'äº§å“': 'äº§å“ç»ç†', 'äº§å“è®¾è®¡': 'äº§å“ç»ç†', 'pm': 'äº§å“ç»ç†',
        'è¿è¥': 'è¿è¥ä¸“å‘˜', 'æ–°åª’ä½“': 'æ–°åª’ä½“è¿è¥', 'å†…å®¹è¿è¥': 'å†…å®¹è¿è¥',
        'é”€å”®': 'é”€å”®ä»£è¡¨', 'ä¸šåŠ¡å‘˜': 'é”€å”®ä»£è¡¨', 'bd': 'å•†åŠ¡æ‹“å±•',
        'äººäº‹': 'äººåŠ›èµ„æº', 'hr': 'äººåŠ›èµ„æº', 'æ‹›è˜': 'æ‹›è˜ä¸“å‘˜',
        'è´¢åŠ¡': 'è´¢åŠ¡ä¼šè®¡', 'ä¼šè®¡': 'è´¢åŠ¡ä¼šè®¡', 'å‡ºçº³': 'è´¢åŠ¡ä¼šè®¡',
        'è¡Œæ”¿': 'è¡Œæ”¿ä¸“å‘˜', 'æ–‡å‘˜': 'è¡Œæ”¿ä¸“å‘˜', 'åŠ©ç†': 'è¡Œæ”¿åŠ©ç†'
    }
    
    # ç§»é™¤æ— å…³å­—ç¬¦
    clean_position = re.sub(r'[ã€/ï¼ˆï¼‰()ã€ã€‘\[\]\s]', '', position).lower()
    
    # åº”ç”¨æ˜ å°„
    for key, value in position_mapping.items():
        if key in clean_position:
            return value
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„æ˜ å°„ï¼Œè¿”å›åŸå§‹å€¼
    return position

def parse_document(text):
    """ä»æ±‚èŒè€…ç®€å†æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯"""
    info = {
        'å§“å': '',
        'å¹´é¾„': '',
        'æ€§åˆ«': '',
        'å­¦å†': '',
        'ä¸“ä¸š': '',
        'å·¥ä½œç»éªŒ': '',
        'æœŸæœ›è–ªèµ„': '',
        'æ±‚èŒå²—ä½': '',
        # 'æŠ€èƒ½': '',
        'è”ç³»æ–¹å¼': ''
    }
    
    # å§“åæå–
    name_match = re.search(r'(å§“å|åå­—|ä¸ªäººå§“å|å€™é€‰äººå§“å)[ï¼š:]\s*([\u4e00-\u9fa5A-Za-zÂ·]+)', text)
    if name_match:
        info['å§“å'] = name_match.group(2)
    
    # å¹´é¾„æå–
    age_match = re.search(r'(å¹´é¾„|å²æ•°|å‡ºç”Ÿå¹´ä»½)[ï¼š:]\s*(\d+)', text)
    if age_match:
        info['å¹´é¾„'] = age_match.group(2)
    
    # æ€§åˆ«æå–
    gender_match = re.search(r'(æ€§åˆ«)[ï¼š:]\s*([ç”·å¥³])', text)
    if gender_match:
        info['æ€§åˆ«'] = gender_match.group(2)
    
    # å­¦å†æå–
    education_match = re.search(r'(å­¦å†|æ•™è‚²èƒŒæ™¯|æœ€é«˜å­¦å†)[ï¼š:]\s*([\u4e00-\u9fa5]+)', text)
    if education_match:
        info['å­¦å†'] = education_match.group(2)
    
    # ä¸“ä¸šæå–
    major_match = re.search(r'(ä¸“ä¸š|æ‰€å­¦ä¸“ä¸š|ä¸»ä¿®ä¸“ä¸š)[ï¼š:]\s*([\u4e00-\u9fa5A-Za-z]+)', text)
    if major_match:
        info['ä¸“ä¸š'] = major_match.group(2)
    
    # å·¥ä½œç»éªŒæå–
    exp_match = re.search(r'(å·¥ä½œç»éªŒ|å·¥ä½œå¹´é™|ä»ä¸šæ—¶é—´)[ï¼š:]\s*(\d+)', text)
    if exp_match:
        info['å·¥ä½œç»éªŒ'] = exp_match.group(2) + "å¹´"
    
    # æœŸæœ›è–ªèµ„æå– - æ”¯æŒä¸­æ–‡æè¿°
    salary_match = re.search(r'(æœŸæœ›è–ªèµ„|è–ªèµ„è¦æ±‚|æœŸæœ›æœˆè–ª|æœŸæœ›å¹´è–ª)[ï¼š:]\s*([\d\-~ï½kKä¸‡åº•è–ªææˆè–ªé‡‘å·¥èµ„å¾…é‡è–ª\+ï¼‹åŠ ]+)', text)
    if salary_match:
        info['æœŸæœ›è–ªèµ„'] = salary_match.group(2).strip()
    
    # æ±‚èŒå²—ä½æå– - å¢å¼ºç‰ˆ
    position_patterns = [
        r'(æ±‚èŒæ„å‘|åº”è˜èŒä½|ç”³è¯·èŒä½|æœŸæœ›èŒä½|ç›®æ ‡å²—ä½|æ±‚èŒå²—ä½)[ï¼š:\s]*([\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()ã€/]+)',
        r'(æœŸæœ›å·¥ä½œ|æ„å‘å²—ä½|å²—ä½æ„å‘)[ï¼š:\s]*([\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()ã€/]+)',
        r'(ç”³è¯·|åº”è˜|æ±‚èŒ|èŒä½)[ï¼š:\s]*([\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()ã€/]+)',
        r'^[ \t]*(èŒä½|å²—ä½)[ï¼š:\s]*([\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()ã€/]+)',
    ]
    
    position_found = False
    for pattern in position_patterns:
        match = re.search(pattern, text)
        if match:
            position = match.group(2).strip()
            position = re.sub(r'^[ï¼š:\s]+', '', position)
            info['æ±‚èŒå²—ä½'] = position
            position_found = True
            break
    
    # å¦‚æœæœªåŒ¹é…åˆ°ï¼Œå°è¯•è·¨è¡ŒåŒ¹é…
    if not position_found:
        match = re.search(
            r'(æ±‚èŒæ„å‘|åº”è˜èŒä½|ç”³è¯·èŒä½|æœŸæœ›èŒä½|ç›®æ ‡å²—ä½)[ï¼š:\s]*(.*?)(?=\n|$)', 
            text, 
            re.DOTALL
        )
        if match:
            position = match.group(2).strip()
            position = re.split(r'[\n\r]+', position)[0]
            info['æ±‚èŒå²—ä½'] = position
    
    # æ ‡å‡†åŒ–å²—ä½åç§°
    info['æ±‚èŒå²—ä½'] = normalize_position(info['æ±‚èŒå²—ä½'])
    
    # # æŠ€èƒ½æå–
    # skill_match = re.findall(r'(ç²¾é€š|ç†Ÿæ‚‰|æŒæ¡|æ“…é•¿)\s*([\u4e00-\u9fa5A-Za-z0-9#+]+)', text)
    # if skill_match:
    #     info['æŠ€èƒ½'] = "ã€".join([s[1] for s in skill_match])
    
    # è”ç³»æ–¹å¼æå–
    contact_match = re.search(r'(ç”µè¯|æ‰‹æœº|è”ç³»æ–¹å¼|è”ç³»ç”µè¯)[ï¼š:]\s*([\d\-]+)', text)
    if contact_match:
        info['è”ç³»æ–¹å¼'] = contact_match.group(2)
    else:
        email_match = re.search(r'é‚®ç®±[ï¼š:]\s*([\w\.-]+@[\w\.-]+)', text)
        if email_match:
            info['è”ç³»æ–¹å¼'] = email_match.group(1)
    
    return info

def parse_job_document(text):
    """ä»ä¼ä¸šæ–‡æ¡£æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯"""
    info = {
        'ä¼ä¸šåç§°': '',
        'æ‹›è˜å²—ä½': '',
        'å­¦å†è¦æ±‚': '',
        'è–ªèµ„èŒƒå›´': '',
        'å·¥ä½œç»éªŒè¦æ±‚': '',
        'æ€§åˆ«è¦æ±‚': '',
        # 'èŒä½æè¿°': ''
    }
    
    # ä¼ä¸šåç§°æå–
    company_match = re.search(r'(å…¬å¸åç§°|ä¼ä¸šåç§°|å…¬å¸|æ‹›è˜å•ä½)[ï¼š:]\s*([\u4e00-\u9fa5A-Za-z0-9ï¼ˆï¼‰()]+)', text)
    if company_match:
        info['ä¼ä¸šåç§°'] = company_match.group(2)
    
    # æ‹›è˜å²—ä½
    position_match = re.search(r'(å²—ä½åç§°|æ‹›è˜å²—ä½|èŒä½åç§°|å²—ä½|æ‹›è˜èŒä½)[ï¼š:]\s*([\u4e00-\u9fa5A-Za-z0-9ã€/]+)', text)
    if position_match:
        position = position_match.group(2).strip()
        info['æ‹›è˜å²—ä½'] = position
    
    # æ ‡å‡†åŒ–å²—ä½åç§°
    info['æ‹›è˜å²—ä½'] = normalize_position(info['æ‹›è˜å²—ä½'])
    
    # å­¦å†è¦æ±‚
    education_match = re.search(r'(å­¦å†è¦æ±‚|å­¦å†|æ•™è‚²èƒŒæ™¯è¦æ±‚)[ï¼š:]\s*([\u4e00-\u9fa5]+)', text)
    if education_match:
        info['å­¦å†è¦æ±‚'] = education_match.group(2)
    
    # è–ªèµ„èŒƒå›´æå– - æ”¯æŒä¸­æ–‡æè¿°
    salary_match = re.search(r'(è–ªèµ„èŒƒå›´|è–ªèµ„|å·¥èµ„|è–ªé…¬èŒƒå›´)[ï¼š:]\s*([\d\-~ï½kKä¸‡åº•è–ªææˆè–ªé‡‘å·¥èµ„å¾…é‡è–ª\+ï¼‹åŠ ]+)', text)
    if salary_match:
        info['è–ªèµ„èŒƒå›´'] = salary_match.group(2).strip()
    
    # å·¥ä½œç»éªŒè¦æ±‚
    exp_match = re.search(r'(å·¥ä½œç»éªŒè¦æ±‚|å·¥ä½œç»éªŒ|å·¥ä½œå¹´é™|ä»ä¸šå¹´é™)[ï¼š:]\s*(\d+)', text)
    if exp_match:
        info['å·¥ä½œç»éªŒè¦æ±‚'] = exp_match.group(2) + "å¹´"
    
    # æ€§åˆ«è¦æ±‚
    gender_match = re.search(r'(æ€§åˆ«è¦æ±‚|æ€§åˆ«)[ï¼š:]\s*([ç”·å¥³ä¸é™]+)', text)
    if gender_match:
        info['æ€§åˆ«è¦æ±‚'] = gender_match.group(2)
    
    # # èŒä½æè¿°ï¼ˆæå–å‰100å­—ï¼‰
    # desc_match = re.search(r'(èŒä½æè¿°|å²—ä½èŒè´£|å·¥ä½œå†…å®¹)[ï¼š:]\s*(.{1,1000})', text)
    # if desc_match:
    #     info['èŒä½æè¿°'] = desc_match.group(2)
    
    return info

def calculate_position_similarity(pos1, pos2):
    """è®¡ç®—ä¸¤ä¸ªå²—ä½åç§°çš„ç›¸ä¼¼åº¦ (0-1)"""
    if not pos1 or not pos2:
        return 0.0
    
    # å®Œå…¨åŒ¹é…
    if pos1 == pos2:
        return 1.0
    
    # åŒ…å«å…³ç³»æ£€æŸ¥
    if pos1 in pos2 or pos2 in pos1:
        return 0.7
    
    # ä½¿ç”¨difflibè®¡ç®—åºåˆ—åŒ¹é…åº¦
    seq_matcher = difflib.SequenceMatcher(None, pos1, pos2)
    similarity = seq_matcher.ratio()
    
    # å…³é”®è¯åŒ¹é…å¢å¼º
    common_keywords = 0
    keywords = ['å¼€å‘', 'è®¾è®¡', 'é”€å”®', 'ç®¡ç†', 'è¿è¥', 'åˆ†æ', 'æµ‹è¯•', 'äº§å“', 'å¸‚åœº', 'å®¢æœ']
    
    for kw in keywords:
        if kw in pos1 and kw in pos2:
            common_keywords += 1
            # æ¯æœ‰ä¸€ä¸ªå…±åŒå…³é”®è¯ï¼Œå¢åŠ ç›¸ä¼¼åº¦
            similarity += 0.1
    
    # é™åˆ¶åœ¨0-1èŒƒå›´å†…
    return min(max(similarity, 0.0), 1.0)

    
    return 0  # é»˜è®¤æœ€ä½ç­‰çº§

def match_applicant_to_job(applicant_info, job_info):
    """åŒ¹é…æ±‚èŒè€…ä¸ä¼ä¸šéœ€æ±‚ - å…³é”®æŒ‡æ ‡ä¸åŒ¹é…æ—¶å¤§å¹…é™ä½æ•´ä½“åŒ¹é…åº¦"""
    match_result = {
        'å­¦å†åŒ¹é…': 'æœªè¯„ä¼°',
        'è–ªèµ„åŒ¹é…': 'æœªè¯„ä¼°',
        'å²—ä½åŒ¹é…': 'æœªè¯„ä¼°',
        'æ€§åˆ«åŒ¹é…': 'æœªè¯„ä¼°',
        'å·¥ä½œç»éªŒåŒ¹é…': 'æœªè¯„ä¼°',
        'æ•´ä½“åŒ¹é…åº¦': 'æœªè¯„ä¼°',
        'å²—ä½ç›¸ä¼¼åº¦': '0%'
    }
    
    # å­¦å†åŒ¹é…
    education_levels = {
    'åšå£«': 5, 'åšå£«ç ”ç©¶ç”Ÿ': 5, 'åšå£«åŠä»¥ä¸Š': 5,
    'ç¡•å£«': 4, 'ç¡•å£«ç ”ç©¶ç”Ÿ': 4, 'ç¡•å£«åŠä»¥ä¸Š': 4,
    'æœ¬ç§‘': 3, 'å­¦å£«': 3, 'å¤§å­¦': 3, 'æœ¬ç§‘åŠä»¥ä¸Š': 3,
    'å¤§ä¸“': 2, 'ä¸“ç§‘': 2, 'å¤§ä¸“åŠä»¥ä¸Š': 2,
    'é«˜ä¸­': 1, 'ä¸­ä¸“': 1, 'èŒé«˜': 1, 'é«˜ä¸­åŠä»¥ä¸Š': 1,
    'åˆä¸­': 0
}
    
    # ä¿®æ”¹å­¦å†åŒ¹é…é€»è¾‘
    def get_education_level(edu_str):
        """ä»å­¦å†å­—ç¬¦ä¸²ä¸­æå–æ ¸å¿ƒç­‰çº§"""
        # é¦–å…ˆæ£€æŸ¥æ•´ä¸ªå­—ç¬¦ä¸²æ˜¯å¦åœ¨å­—å…¸ä¸­
        if edu_str in education_levels:
            return education_levels[edu_str]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«"åŠä»¥ä¸Š"ã€"ä»¥ä¸Š"ç­‰è¦æ±‚
        if "åŠä»¥ä¸Š" in edu_str or "ä»¥ä¸Š" in edu_str:
            # æå–æ ¸å¿ƒå­¦å†è¯
            core_edu = re.sub(r'[åŠä»¥]ä¸Š', '', edu_str)
            if core_edu in education_levels:
                return education_levels[core_edu]
        
        # æœ€åå°è¯•éƒ¨åˆ†åŒ¹é…
        for level in education_levels:
            if level in edu_str and level != "ä»¥ä¸Š":  # é¿å…è¯¯åŒ¹é…
                return education_levels[level]
        
        return 0  # é»˜è®¤æœ€ä½ç­‰çº§
    
    applicant_edu = applicant_info.get('å­¦å†', '')
    job_edu = job_info.get('å­¦å†è¦æ±‚', '')
    
    if applicant_edu and job_edu:
        applicant_level = get_education_level(applicant_edu)
        job_level = get_education_level(job_edu)
        
        # æ£€æŸ¥ä¼ä¸šè¦æ±‚æ˜¯å¦åŒ…å«"åŠä»¥ä¸Š"è¦æ±‚
        if "åŠä»¥ä¸Š" in job_edu or "ä»¥ä¸Š" in job_edu:
            # å¯¹äº"åŠä»¥ä¸Š"è¦æ±‚ï¼Œæ±‚èŒè€…ç­‰çº§å¿…é¡»è¾¾åˆ°æˆ–è¶…è¿‡
            match_result['å­¦å†åŒ¹é…'] = 'ç¬¦åˆ' if applicant_level >= job_level else 'ä¸ç¬¦åˆ'
        else:
            # å¯¹äºæ˜ç¡®è¦æ±‚ï¼Œå¿…é¡»å®Œå…¨åŒ¹é…
            match_result['å­¦å†åŒ¹é…'] = 'ç¬¦åˆ' if applicant_level == job_level else 'ä¸ç¬¦åˆ'
    
    # è–ªèµ„åŒ¹é…
    applicant_salary = applicant_info.get('æœŸæœ›è–ªèµ„', '')
    job_salary = job_info.get('è–ªèµ„èŒƒå›´', '')
    
    if applicant_salary and job_salary:
        # ç®€åŒ–å¤„ç†ï¼šæå–è–ªèµ„æ•°å­—
        app_min, app_max = extract_salary_range(applicant_salary)
        job_min, job_max = extract_salary_range(job_salary)
        
        if app_min is not None and app_max is not None and job_min is not None and job_max is not None:
            # æ£€æŸ¥æ±‚èŒè€…æœŸæœ›æ˜¯å¦åœ¨ä¼ä¸šèŒƒå›´å†…
            if app_min >= job_min and app_max <= job_max:
                match_result['è–ªèµ„åŒ¹é…'] = 'ç¬¦åˆ'
            elif app_min <= job_max and app_max >= job_min:
                match_result['è–ªèµ„åŒ¹é…'] = 'éƒ¨åˆ†ç¬¦åˆ'
            else:
                match_result['è–ªèµ„åŒ¹é…'] = 'ä¸ç¬¦åˆ'
        else:
            match_result['è–ªèµ„åŒ¹é…'] = 'æ— æ³•è¯„ä¼°'
    
    # å²—ä½åŒ¹é…
    applicant_position = applicant_info.get('æ±‚èŒå²—ä½', '')
    job_position = job_info.get('æ‹›è˜å²—ä½', '')
    
    # è®¡ç®—å²—ä½ç›¸ä¼¼åº¦
    position_similarity = calculate_position_similarity(applicant_position, job_position)
    match_result['å²—ä½ç›¸ä¼¼åº¦'] = f"{position_similarity * 100:.0f}%"
    
    if applicant_position and job_position:
        # åŸºäºç›¸ä¼¼åº¦åˆ¤æ–­åŒ¹é…ç¨‹åº¦
        if position_similarity >= 0.85:
            match_result['å²—ä½åŒ¹é…'] = 'é«˜åº¦ç¬¦åˆ'
        elif position_similarity >= 0.6:
            match_result['å²—ä½åŒ¹é…'] = 'éƒ¨åˆ†ç¬¦åˆ'
        else:
            match_result['å²—ä½åŒ¹é…'] = 'ä¸ç¬¦åˆ'
    else:
        match_result['å²—ä½åŒ¹é…'] = 'æœªè¯„ä¼°'
    
    # æ€§åˆ«åŒ¹é…
    applicant_gender = applicant_info.get('æ€§åˆ«', '')
    job_gender = job_info.get('æ€§åˆ«è¦æ±‚', '')
    
    if applicant_gender and job_gender:
        if job_gender == 'ä¸é™' or job_gender == 'æ— è¦æ±‚' or 'ä¸é™' in job_gender:
            match_result['æ€§åˆ«åŒ¹é…'] = 'ç¬¦åˆ'
        else:
            match_result['æ€§åˆ«åŒ¹é…'] = 'ç¬¦åˆ' if applicant_gender == job_gender else 'ä¸ç¬¦åˆ'
    
    # å·¥ä½œç»éªŒåŒ¹é…
    applicant_exp = applicant_info.get('å·¥ä½œç»éªŒ', '')
    job_exp = job_info.get('å·¥ä½œç»éªŒè¦æ±‚', '')
    
    if applicant_exp and job_exp:
        try:
            app_exp_years = int(re.search(r'\d+', applicant_exp).group())
            job_exp_years = int(re.search(r'\d+', job_exp).group())
            match_result['å·¥ä½œç»éªŒåŒ¹é…'] = 'ç¬¦åˆ' if app_exp_years >= job_exp_years else 'ä¸ç¬¦åˆ'
        except:
            match_result['å·¥ä½œç»éªŒåŒ¹é…'] = 'æ— æ³•è¯„ä¼°'
    
    # è®¡ç®—æ•´ä½“åŒ¹é…åº¦ - å…³é”®æŒ‡æ ‡ä¸åŒ¹é…æ—¶å¤§å¹…é™ä½åŒ¹é…åº¦
    # å®šä¹‰å…³é”®æŒ‡æ ‡å’Œæ™®é€šæŒ‡æ ‡
    critical_fields = ['å²—ä½åŒ¹é…', 'å­¦å†åŒ¹é…']  # å…³é”®æŒ‡æ ‡
    normal_fields = ['è–ªèµ„åŒ¹é…', 'æ€§åˆ«åŒ¹é…', 'å·¥ä½œç»éªŒåŒ¹é…']  # æ™®é€šæŒ‡æ ‡
    
    # å®šä¹‰å„åŒ¹é…ç»“æœçš„æƒé‡
    weight_map = {
        'é«˜åº¦ç¬¦åˆ': 1.0,
        'ç¬¦åˆ': 1.0,
        'éƒ¨åˆ†ç¬¦åˆ': 0.6,
        'ä¸ç¬¦åˆ': 0.0,
        'æ— æ³•è¯„ä¼°': 0.5,  # æ— æ³•è¯„ä¼°æŒ‰50%è®¡åˆ†
        'æœªè¯„ä¼°': 0.0
    }
    
    # å…³é”®æŒ‡æ ‡æƒé‡å› å­ (å½“å…³é”®æŒ‡æ ‡ä¸ç¬¦åˆæ—¶ï¼Œæ•´ä½“åŒ¹é…åº¦å¤§å¹…é™ä½)
    critical_penalty = 0.3  # å…³é”®æŒ‡æ ‡ä¸ç¬¦åˆæ—¶çš„æƒ©ç½šå› å­
    
    # è®¡ç®—åŒ¹é…åº¦
    total_score = 0.0
    max_score = 0.0
    critical_fail = False
    
    # å¤„ç†å…³é”®æŒ‡æ ‡
    for field in critical_fields:
        result = match_result[field]
        if result != 'æœªè¯„ä¼°':
            score = weight_map.get(result, 0.0)
            
            # å¦‚æœå…³é”®æŒ‡æ ‡ä¸ç¬¦åˆï¼Œè®¾ç½®æ ‡å¿—å¹¶åº”ç”¨æƒ©ç½š
            if result == 'ä¸ç¬¦åˆ':
                critical_fail = True
                score *= critical_penalty
            
            total_score += score * 2.0  # å…³é”®æŒ‡æ ‡æƒé‡åŠ å€
            max_score += 2.0
    
    # å¤„ç†æ™®é€šæŒ‡æ ‡
    for field in normal_fields:
        result = match_result[field]
        if result != 'æœªè¯„ä¼°':
            score = weight_map.get(result, 0.0)
            
            # å¦‚æœæœ‰å…³é”®æŒ‡æ ‡ä¸ç¬¦åˆï¼Œæ™®é€šæŒ‡æ ‡å¾—åˆ†ä¹Ÿé™ä½
            if critical_fail:
                score *= critical_penalty
            
            total_score += score
            max_score += 1.0
    
    # è®¡ç®—æ•´ä½“åŒ¹é…åº¦ç™¾åˆ†æ¯”
    if max_score > 0:
        match_percentage = int((total_score / max_score) * 100)
        
        # å¦‚æœå…³é”®æŒ‡æ ‡ä¸ç¬¦åˆï¼ŒåŒ¹é…åº¦ä¸Šé™è®¾ä¸º50%
        if critical_fail and match_percentage > 50:
            match_percentage = 50
            
        match_result['æ•´ä½“åŒ¹é…åº¦'] = f"{match_percentage}%"
    else:
        match_result['æ•´ä½“åŒ¹é…åº¦'] = 'æ— æ³•è®¡ç®—'
    
    return match_result

def extract_salary_range(salary_str):
    """ä»è–ªèµ„å­—ç¬¦ä¸²ä¸­æå–æ•°å­—èŒƒå›´ï¼Œæ”¯æŒä¸­æ–‡æè¿°"""
    # å¤„ç†å¸¸è§è–ªèµ„æ ¼å¼ï¼š10k-20k, 10,000-20,000, 1ä¸‡-2ä¸‡, åº•è–ª10k+ææˆ
    salary_str = salary_str.replace(',', '').replace('ï¼Œ', '')
    
    # ç»Ÿä¸€å•ä½è½¬æ¢ - æå–æ‰€æœ‰æ•°å­—éƒ¨åˆ†
    numbers = []
    if 'ä¸‡' in salary_str or 'k' in salary_str.lower():
        # æŸ¥æ‰¾æ‰€æœ‰æ•°å­—å’Œå•ä½
        num_units = re.findall(r'(\d+\.?\d*)([ä¸‡kK]?)', salary_str)
        for num, unit in num_units:
            num = float(num)
            if unit == 'ä¸‡':
                num *= 10000
            elif unit.lower() == 'k':
                num *= 1000
            numbers.append(num)
    else:
        # æå–çº¯æ•°å­—
        numbers = [float(num) for num in re.findall(r'\d+\.?\d*', salary_str)]
    
    # å¤„ç†æå–åˆ°çš„æ•°å­—
    if numbers:
        if len(numbers) >= 2:
            return min(numbers), max(numbers)
        else:
            return numbers[0], numbers[0]
    
    return None, None

def save_uploaded_file(uploaded_file, file_type):
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    file_ext = uploaded_file.name.split('.')[-1]
    filename = f"{file_type}_{timestamp}.{file_ext}"
    file_path = os.path.join(UPLOAD_DIR, filename)
    
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    return file_path

def main():
    st.title("å°±ä¸šé¢è¯•æ™ºèƒ½ä½“ç³»ç»Ÿ")
    st.subheader("æ±‚èŒè€…ä¸ä¼ä¸šä¿¡æ¯åŒ¹é…å¹³å°")
    
    # åˆå§‹åŒ–session state
    if 'applicant_info' not in st.session_state:
        st.session_state.applicant_info = {}
    if 'job_info' not in st.session_state:
        st.session_state.job_info = {}
    if 'match_result' not in st.session_state:
        st.session_state.match_result = {}
    
    # ä¸Šä¼ åŠŸèƒ½
    st.sidebar.header("æ–‡ä»¶ä¸Šä¼ ")
    upload_option = st.sidebar.radio("é€‰æ‹©ä¸Šä¼ ç±»å‹", ["ä¼ä¸šä¿¡æ¯", "æ±‚èŒè€…ç®€å†"])
    
    if upload_option == "ä¼ä¸šä¿¡æ¯":
        uploaded_file = st.sidebar.file_uploader(
            "ä¸Šä¼ ä¼ä¸šä¿¡æ¯æ–‡æ¡£ (doc, docx, pdf, txt)",
            type=["doc", "docx", "pdf", "txt"]
        )
        
        if uploaded_file:
            file_path = save_uploaded_file(uploaded_file, "job")
            file_ext = file_path.split('.')[-1].lower()
            
            try:
                if file_ext == "pdf":
                    text = extract_text_from_pdf(file_path)
                elif file_ext in ["doc", "docx"]:
                    text = extract_text_from_docx(file_path)
                else:  # txt
                    text = extract_text_from_txt(file_path)
                
                # ä½¿ç”¨ä¼ä¸šæ–‡æ¡£è§£æå‡½æ•°
                st.session_state.job_info = parse_job_document(text)
                
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶åä½œä¸ºä¼ä¸šåç§°
                if not st.session_state.job_info.get('ä¼ä¸šåç§°'):
                    st.session_state.job_info['ä¼ä¸šåç§°'] = uploaded_file.name.split('.')[0]
                
                st.sidebar.success("ä¼ä¸šä¿¡æ¯è§£ææˆåŠŸï¼")
                
            except Exception as e:
                st.sidebar.error(f"æ–‡ä»¶è§£æé”™è¯¯: {str(e)}")
    
    else:  # æ±‚èŒè€…ç®€å†
        uploaded_file = st.sidebar.file_uploader(
            "ä¸Šä¼ æ±‚èŒè€…ç®€å† (doc, docx, pdf, txt)",
            type=["doc", "docx", "pdf", "txt"]
        )
        
        if uploaded_file:
            file_path = save_uploaded_file(uploaded_file, "applicant")
            file_ext = file_path.split('.')[-1].lower()
            
            try:
                if file_ext == "pdf":
                    text = extract_text_from_pdf(file_path)
                elif file_ext in ["doc", "docx"]:
                    text = extract_text_from_docx(file_path)
                else:  # txt
                    text = extract_text_from_txt(file_path)
                
                st.session_state.applicant_info = parse_document(text)
                st.sidebar.success("æ±‚èŒè€…ç®€å†è§£ææˆåŠŸï¼")
                
            except Exception as e:
                st.sidebar.error(f"æ–‡ä»¶è§£æé”™è¯¯: {str(e)}")
    
    # æ˜¾ç¤ºè§£æç»“æœ
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ä¼ä¸šä¿¡æ¯")
        if st.session_state.job_info:
            job_df = pd.DataFrame.from_dict(
                st.session_state.job_info, 
                orient='index', 
                columns=['å€¼']
            )
            st.dataframe(job_df)
        else:
            st.info("è¯·ä¸Šä¼ ä¼ä¸šä¿¡æ¯æ–‡æ¡£")
    
    with col2:
        st.subheader("æ±‚èŒè€…ä¿¡æ¯")
        if st.session_state.applicant_info:
            applicant_df = pd.DataFrame.from_dict(
                st.session_state.applicant_info, 
                orient='index', 
                columns=['å€¼']
            )
            st.dataframe(applicant_df)
        else:
            st.info("è¯·ä¸Šä¼ æ±‚èŒè€…ç®€å†")
    
    # åŒ¹é…æŒ‰é’®
    if st.button("è¿›è¡ŒåŒ¹é…åˆ†æ", use_container_width=True):
        if st.session_state.job_info and st.session_state.applicant_info:
            st.session_state.match_result = match_applicant_to_job(
                st.session_state.applicant_info,
                st.session_state.job_info
            )
            st.success("åŒ¹é…åˆ†æå®Œæˆï¼")
        else:
            st.warning("è¯·å…ˆä¸Šä¼ ä¼ä¸šä¿¡æ¯å’Œæ±‚èŒè€…ç®€å†")
    
    # æ˜¾ç¤ºåŒ¹é…ç»“æœ
    if st.session_state.match_result:
        st.subheader("åŒ¹é…åˆ†æç»“æœ")
        
        # åˆ›å»ºç»“æœæ•°æ®æ¡†ï¼Œæ’é™¤å²—ä½ç›¸ä¼¼åº¦ï¼ˆå°†åœ¨åé¢å•ç‹¬æ˜¾ç¤ºï¼‰
        display_result = {k: v for k, v in st.session_state.match_result.items() if k != 'å²—ä½ç›¸ä¼¼åº¦'}
        match_df = pd.DataFrame.from_dict(
            display_result, 
            orient='index', 
            columns=['ç»“æœ']
        )
        st.dataframe(match_df)
        
        # æ˜¾ç¤ºå²—ä½ç›¸ä¼¼åº¦è¯¦æƒ…
        applicant_position = st.session_state.applicant_info.get('æ±‚èŒå²—ä½', 'æ— ')
        job_position = st.session_state.job_info.get('æ‹›è˜å²—ä½', 'æ— ')
        similarity = st.session_state.match_result.get('å²—ä½ç›¸ä¼¼åº¦', '0%')
        
        st.write(f"**å²—ä½åŒ¹é…è¯¦æƒ…**:")
        st.write(f"- æ±‚èŒè€…å²—ä½: `{applicant_position}`")
        st.write(f"- ä¼ä¸šå²—ä½: `{job_position}`")
        st.write(f"- å²—ä½ç›¸ä¼¼åº¦: `{similarity}`")
        
        # å¯è§†åŒ–åŒ¹é…åº¦
        overall_match = st.session_state.match_result.get('æ•´ä½“åŒ¹é…åº¦', '0%')
        
        # åªæœ‰å½“åŒ¹é…åº¦æ˜¯ç™¾åˆ†æ¯”æ—¶æ‰æ˜¾ç¤ºè¿›åº¦æ¡
        if '%' in overall_match:
            try:
                match_percentage = int(overall_match.strip('%'))
                st.metric("æ•´ä½“åŒ¹é…åº¦", overall_match)
                st.progress(match_percentage / 100)
                
                # å…³é”®æŒ‡æ ‡æ£€æŸ¥
                critical_fail = False
                critical_fields = ['å²—ä½åŒ¹é…', 'å­¦å†åŒ¹é…']
                for field in critical_fields:
                    result = st.session_state.match_result.get(field, '')
                    if 'ä¸ç¬¦åˆ' in result:
                        critical_fail = True
                        st.warning(f"âš ï¸ å…³é”®æŒ‡æ ‡ '{field}' ä¸ç¬¦åˆè¦æ±‚ï¼ŒåŒ¹é…åº¦å¤§å¹…é™ä½")
                
                # åŒ¹é…å»ºè®®
                if match_percentage >= 80:
                    st.success("ğŸ‘ é«˜åº¦åŒ¹é…ï¼šæ±‚èŒè€…éå¸¸é€‚åˆè¯¥èŒä½")
                elif match_percentage >= 60:
                    st.info("ğŸ‘Œ ä¸­åº¦åŒ¹é…ï¼šæ±‚èŒè€…åŸºæœ¬ç¬¦åˆè¦æ±‚")
                elif match_percentage >= 40:
                    st.warning("âš ï¸ ä½åº¦åŒ¹é…ï¼šå­˜åœ¨æ˜æ˜¾ä¸åŒ¹é…é¡¹")
                else:
                    st.error("âŒ ä¸åŒ¹é…ï¼šæ±‚èŒè€…ä¸èŒä½è¦æ±‚å·®è·è¾ƒå¤§")
                    
                # å…³é”®æŒ‡æ ‡ä¸ç¬¦åˆæ—¶çš„ç‰¹æ®Šæç¤º
                if critical_fail and match_percentage > 0:
                    st.error("â›” å…³é”®æŒ‡æ ‡ï¼ˆå²—ä½/å­¦å†ï¼‰ä¸ç¬¦åˆï¼Œæ±‚èŒè€…ä¸ç¬¦åˆä¼ä¸šåŸºæœ¬è¦æ±‚")
                
            except ValueError:
                st.warning("æ— æ³•è®¡ç®—åŒ¹é…åº¦ç™¾åˆ†æ¯”")
        else:
            st.warning(f"åŒ¹é…åº¦æ•°æ®å¼‚å¸¸: {overall_match}")

if __name__ == "__main__":
    main()
    
#streamlit run d:/model/match_job.py